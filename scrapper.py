import os
import requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∫—É–∫–∏ –∑ .env
load_dotenv()

def get_text_from_url(url):
    print(f"üì° Requests (Cookie Mode): –°—Ç—É–∫–∞—é –Ω–∞ {url}...")

    # –ë–µ—Ä–µ–º–æ –¥–∞–Ω—ñ –∑ .env
    cookie_str = os.getenv("NOVELBIN_COOKIE")
    user_agent = os.getenv("MY_USER_AGENT")

    if not cookie_str or not user_agent:
        print("‚ùå –ü–û–ú–ò–õ–ö–ê: –ù–µ –∑–∞–ø–æ–≤–Ω–µ–Ω—ñ NOVELBIN_COOKIE –∞–±–æ MY_USER_AGENT –≤ .env —Ñ–∞–π–ª—ñ!")
        return None, None

    # –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ —Ä—è–¥–æ–∫ –∫—É–∫—ñ–≤ —É —Å–ª–æ–≤–Ω–∏–∫
    cookies = {}
    for item in cookie_str.split(';'):
        if '=' in item:
            name, value = item.strip().split('=', 1)
            cookies[name] = value

    headers = {
        'User-Agent': user_agent,
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Referer': 'https://novelbin.com/',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'same-origin',
        'Sec-Fetch-User': '?1',
    }

    try:
        # –†–æ–±–∏–º–æ –∑–∞–ø–∏—Ç –∑ —Ç–≤–æ—ó–º–∏ –∫—É–∫–∞–º–∏ (–æ–±—Ö–æ–¥–∏–º–æ Cloudflare)
        response = requests.get(url, headers=headers, cookies=cookies, timeout=15)
        
        if response.status_code == 403:
            print("‚ùå –ü–æ–º–∏–ª–∫–∞ 403. –ö—É–∫–∏ –ø—Ä–æ—Å—Ç—Ä–æ—á–µ–Ω—ñ –∞–±–æ IP –∑–∞–±–∞–Ω–µ–Ω–æ.")
            print("üí° –ü–æ—Ä–∞–¥–∞: –û–Ω–æ–≤–∏ NOVELBIN_COOKIE –≤ .env –∑—ñ —Å–≤—ñ–∂–æ–≥–æ –±—Ä–∞—É–∑–µ—Ä–∞.")
            return None, None
            
        if response.status_code != 200:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –ö–æ–¥ {response.status_code}")
            return None, None

        soup = BeautifulSoup(response.text, 'html.parser')
        
        # –®—É–∫–∞—î–º–æ —Ç–µ–∫—Å—Ç
        content_div = soup.find('div', id='chr-content')
        if not content_div:
            content_div = soup.find('div', id='chapter-content')
            
        if not content_div:
            print("‚ùå –¢–µ–∫—Å—Ç –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ (–º–æ–∂–ª–∏–≤–æ, –∫—É–∫–∏ –Ω–µ —Å–ø—Ä–∞—Ü—é–≤–∞–ª–∏ –∞–±–æ –≤–µ—Ä—Å—Ç–∫–∞ –∑–º—ñ–Ω–∏–ª–∞—Å—è).")
            return None, None

        # –û—á–∏—â–∞—î–º–æ –≤—ñ–¥ —Å–º—ñ—Ç—Ç—è (—Ä–µ–∫–ª–∞–º–∞, –ø—Ä–∏—Ö–æ–≤–∞–Ω—ñ –∞–±–∑–∞—Ü–∏)
        for tag in content_div(["script", "style", "div", "a", "button", "iframe", "p.display-none"]):
            tag.decompose()
            
        text = content_div.get_text(separator='\n\n').strip()
        
        title = "Shadow Slave Chapter"
        title_tag = soup.find('span', class_='chr-text')
        if title_tag:
            title = title_tag.text.strip()
            
        print(f"‚úÖ –£—Å–ø—ñ—Ö! –°–∫–∞—á–∞–Ω–æ —Å–∏–º–≤–æ–ª—ñ–≤: {len(text)}")
        return title, text

    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
        return None, None

def get_novelbin_chapter(chapter_number):
    url = f"https://novelbin.com/b/shadow-slave/chapter-{chapter_number}"
    return get_text_from_url(url)